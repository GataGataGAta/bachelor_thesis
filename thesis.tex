% Last updated at 2024/12/10 09:39:36
\documentclass[12pt,a4j]{ltjsreport}
\usepackage{ltklthesis}
\usepackage{multirow}
\usepackage{float}
\usepackage{amsmath}

\begin{document}

\type{B} %卒論はB，修論はM
\author{山形隼士}
\id{2503} %学籍番号
\fyear{2025} %修了・卒業年(修了・卒業式が2025年3月なら2025)
\title{審判ジェスチャに着目した\\バスケットボールシュート種類\\判別手法}
\abstract{
近年，スポーツアナリティクスの発展に伴い，バスケットボール競技におけるスタッツの重要性が高まっており，スタッツを収集することを自動化することが求められている．特に映像解析を用いたシュート種類の自動判別においては，選手位置をコート平面へ投影する手法が一般的だが，オクルージョンやホモグラフィ変換の誤差により正しく判別できないという課題があった．
本研究ではこの課題に対し，審判のジェスチャに着目し，位置推定と骨格認識を統合した新たな判別手法を提案する．具体的には，YOLOv8-poseを用いて審判の手首と肩の座標を検出し，3ポイントシュート特有のジェスチャを判別する．提案手法は，位置推定による判別を優先し，未検出時に限りジェスチャの情報を補完的に利用することで，位置推定による判別の欠点を補うアルゴリズムである．
評価実験の結果，統合手法の正解率は2点シュートで96.95\%，3点シュートで95.12\%を達成した．これは位置推定単体と比較してそれぞれ約7.7ポイント，4.0ポイントの向上である．本結果は，審判のジェスチャを判別することが位置情報の欠損を補う有効な特徴量であり，統合手法がシステムの検出率を向上させることを示している．
}

\maketitle

\chapter{はじめに}
近年，スポーツアナリティクスの分野は著しい発展を遂げており，バスケットボール競技においても，各選手のパフォーマンスを詳細に表すスタッツと呼ばれるデータを用いた戦術分析や選手評価が一般化している．これらの指標は，シュート成功率，リバウンド数，アシスト数などの定量的データに基づいており，チームの勝利に直結する重要な要素となる．

一方で，現状のスタッツ収集は主に人力で行われている点や，収集に用いるアプリケーションが競技カテゴリごとに異なり統一されていないなどの課題がある．そのため，スタッツ収集のプロセスを自動化する必要性が高まっている．

この点に関して，Versnikら\cite{stats}は試合映像を入力とし，物体検出や追跡技術を用いてスタッツを自動生成するシステムを提案している．しかし，映像内の選手位置情報のみから，2ポイントシュートか3ポイントシュートかというシュートの種類を判別する手法には技術的な限界が存在する．具体的には，足元の位置検出における微小な誤差や，カメラアングルによるホモグラフィ変換の歪み，あるいはディフェンス選手によるオクルージョンが発生し，物体検出での未検出が起こった場合，3ポイントライン際での判別精度が著しく低下するという課題がある．

この課題に対し，本研究では審判の情報に着目する．バスケットボールの審判は，シュートが放たれた際，その放たれた位置や状況に応じて，2ポイントあるいは3ポイントを示す特定のハンドジェスチャを行う規定がある．すなわち，審判の動作は，シュートの種類を決定づける信頼性の高い視覚情報であると言える．

以上の背景から，本研究では，従来の選手位置座標のみに依存した判別手法に加え，シュート時における審判のジェスチャ認識を導入した新たな統合判別手法を提案する．審判のジェスチャを統合することで，上記のような判別困難な状況において，シュート種類の判別精度がどの程度改善されるかを検証し，その有効性を明らかにする．

本論文は全5章で構成する．第2章では，関連研究と本研究の目的について述べる．第3章では，本研究で提案するシュート種類の判別手法の詳細を述べる．第4章では，評価と結果について述べる．第5章では，本研究のまとめについて述べる．

\chapter{コンピュータビジョンを用いた\\バスケットボールの研究} 

\section{バスケットボール競技}
バスケットボールは，1チーム5名のプレイヤーからなる2つのチームが，コートの両端に設置されたリング（バスケット）へボールを投じ，その通過数によって得点を競う球技である ．コート上には計10名の選手が存在し，攻守を激しく入れ替えながら試合が展開される ．

攻撃側の選手がリングに向けてボールを投じる動作を「シュート」と呼び，その動作を行う選手を「シューター」と呼ぶ ．得点の種類はシュートが放たれた位置によって厳密に区分されており，その基準となるのがゴールの中心から6.75m離れた位置に描かれた「3ポイントライン」である ．図1にバスケットボールのコート図を示す ．このラインを境界として，ラインの内側（2ポイントエリア）から放たれたシュートは「2ポイントシュート」，外側（3ポイントエリア）から放たれたシュートは「3ポイントシュート」と定義される ．
\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=0.8\linewidth]{image/court.pdf}
  
  \caption{バスケットボールコートの図}
  \label{fig:basketball_court}
\end{figure}

試合の判別および進行管理は，最大3名の審判員（レフェリー）によって行われる ．審判は，ファウルやバイオレーションなどの反則行為に対する判別だけでなく，試合中に発生するあらゆる事象に対して規定のハンドジェスチャを用いて視覚的に伝達を行う役割を担う ．特に，本研究で着目するシュート動作に関しては，シュートが放たれた瞬間にその試行が2ポイントであるか3ポイントであるかを明確にするため，審判はそれぞれに対応した異なるジェスチャを提示する規定となっている ．図2にシュートにおける審判のジェスチャを示す ．

\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}
  % 高さを揃えるために共通の高さを指定
  \newlength{\imgheight}
  \setlength{\imgheight}{4.0cm} % ← 縮小 (もともと4cm)
  
  % --- 左側の画像 ---
  \begin{minipage}[t]{0.30\linewidth} 
    \centering
    \raisebox{3mm}{\includegraphics[height=\imgheight]{image/2pt.pdf}}
  \end{minipage}
  \hspace{0.5em} % ← 画像の間隔を微調整
  % --- 右側の画像 ---
  \begin{minipage}[t]{0.30\linewidth}
    \centering
    \includegraphics[height=\imgheight]{image/3pt.pdf}
    % \label{fig:3pt} % 同上
  \end{minipage}
  
  \caption{2ポイントシュート（左）および3ポイントシュート（右）のジェスチャ}
  \label{fig:shoot_gesture}
\end{figure}


また，現代のバスケットボール競技においては，試合の勝敗だけでなく，各選手の貢献度やパフォーマンスを詳細に可視化するために「スタッツ（Stats）」と呼ばれるデータが重要視されている．スタッツとは，その選手が何本シュートを決めたか，何回反則を犯したかなどの詳細なプレイ記録の総称である ．図2.3にスタッツの例を示す．表中の数値は選手の成績を表しており，例えば図中の「MIN」の個所は出場時間，「A（Attempted）」の箇所はシュートを打った数，「M（Made）」の箇所はシュートを決めた数を示している ．現状，これらのスタッツ収集は，専門の記録員がシステムを用いて行っており，依然として人の目視による判断と手動入力に依存している．

\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=1.0\linewidth]{image/stats.pdf}
  
  \caption{スタッツの例}
  \label{fig:stats}
\end{figure}

\section{関連研究}
本節では，バスケットボールにおけるスタッツの自動収集および審判のジェスチャ認識に関する既存研究を概観し，それぞれの提案手法の詳細と，本研究の立場から見た課題（欠点）について述べる．

\subsection{スタッツの自動収集}
VeršnikとŠajn（2023）は，NBAの放送映像を入力とし，ディープラーニングを用いて選手やボールを検出し，試合の統計データ（スタッツ）を自動的に収集するシステムを提案している\cite{stats}． 彼らの手法では，まず物体検出アルゴリズムであるYOLOを用いて選手を検出し，追跡アルゴリズムであるDeepSORTと組み合わせることで各選手のトラッキングを行っている．さらに，DeepSORT単体では選手同士が交差した際などにIDが入れ替わりチーム分類を誤る問題があったため，MobileNetV2を用いた画像分類モデルを追加で導入し，チーム分類の精度を99.41\%まで向上させた。 シュート判別においては，ホモグラフィ変換を用いて映像内の3次元座標をコートの2次元平面座標へ変換し，ボールとゴールの位置関係および選手の足元の位置に基づいて，3ポイント，2ポイント，フリースローの判別を行っている．

しかしながら，本手法にはシュート判別の精度が低いという重大な課題がある．彼らの実験結果によると，シュート試投数の検出精度は高いものの，シュート成功（の判別や種別の分類において誤検出が目立った．具体的には，3ポイントシュートの成功検出精度は53.4\%に留まり，試投の検出精度も63.3\%であった．この精度の低さは，主にホモグラフィ変換の不安定さに起因している．特にコートの片側における変換行列の計算誤差が大きく，フリースローの場面において，選手の位置が3ポイントラインの外側であると誤って計算され，3ポイントシュートとして誤分類される事例が多発したことが報告されている．このように，画像座標から物理座標への変換に依存したシュート判別は，カメラアングルの変化やオクルージョンに対して脆弱であり，実用的なスタッツ収集には不十分である．

\subsection{HOG，LBP特徴量とSVMによる審判ジェスチャ認識}
Žemgulysら（2020）は，コンピュータビジョンを用いてバスケットボールの試合映像から審判のジェスチャを認識する手法を提案している\cite{wang}．彼らは，スポーツ映像のようなノイズの多い実環境下での認識を実現するため，画像の前処理としてRGB画像をグレースケール化し，Sobelフィルタを用いてエッジ検出を行うことで，照明変動の影響を軽減している．特徴量抽出には，形状情報を捉えるHOGと，テクスチャ情報を捉えるLBPの2種類を採用し，これらをSVMおよびランダムフォレストで分類する実験を行った．実験の結果，LBP特徴量とSVMを組み合わせたモデルが最も高い性能を示し，全クラス平均で95.6\%の認識精度を達成した．特に3ポイントシュート成功のジェスチャに関しては，正面からの映像で97.7\%という極めて高い精度で認識できている．

しかしながら，この研究の課題は，認識したジェスチャをスタッツの自動集計やシュート判別の結果確定に活用していない点にある．本研究の主眼は，あくまで審判と記録員間のコミュニケーションミスを減らすためのジェスチャの認識そのものに置かれている．そのため，認識された3ポイント成功のジェスチャが，実際の得点加算処理や，Veršnikらの研究で課題とされたようなシュートが本当に入ったかどうかの判別の補正に利用されるシステム構成にはなっていない．単独のジェスチャ認識に留まっており，試合のコンテキストと統合されたスタッツ生成システムとしては機能していない．

\subsection{マルチスケール時空間特徴を用いた深層学習による審判ジェスチャ認識}
Wangら（2024）は，マルチスケールの時空間特徴を活用し，複雑なバスケットボールのシーンにおいて審判のジェスチャをリアルタイムで認識するシステムを提案している\cite{zemgulys}．
彼らは「GIS-ResT」と呼ばれる軽量なネットワークモデルを構築した．これは，時間領域のマルチスケール時空間畳み込みモジュールと，大域的な情報を同期させるためのチャネル注意機構を組み合わせたものである．
このモデルは，従来の3D畳み込みと比較して計算コストを大幅に削減しつつ，ジェスチャの詳細な特徴を捉えることに成功しており，平均認識率は92.20\%に達している．また，このシステムはモバイル端末やWebページ上での動作を想定して実装されており，選手や観客などユーザーに対して認識したジェスチャの種類を音声でブロードキャストする機能を有している。

この研究もまた，スタッツの収集やシュート判別のロジックにジェスチャを利用していない点が課題である．本システムの目的は，聴覚や視覚に障害を持つ観客への支援や，記録員が見逃した判別の確認，あるいはコーチや選手がビデオ分析を行う際の該当シーンの検索補助に限定されている．システムはジェスチャを分類して提示する補助機能として設計されており，例えば，審判が2点のジェスチャをしたから，自動的にスコアに2点を加算するといった，スタッツ管理の自動化に直結する機能は実装されていない．

\section{研究の目的}
前節で述べたように，Veršnikら\cite{stats}による先行研究では，ホモグラフィ変換を用いて映像内の座標をコート平面上の座標へ変換し，その位置情報に基づいてシュート種別の判別を行っていた．しかし，この手法はカメラアングルやレンズの歪みの影響を受けやすく，特にコートの奥側や端部において変換行列の計算誤差が増大するという欠点を抱えていた．その結果，本来はフリースローである事象を3ポイントシュートとして誤認識するなど，シュート種類の判別精度が低下する課題が未解決のまま残されている．

一方で，バスケットボールの競技規則において，審判は3ポイントシュートの試投時および成功時に，2ポイントシュートは成功時のみに，その種類を特定するための明確なジェスチャを行うことが義務付けられている．Žemgulysら\cite{wang}やWangら\cite{zemgulys}の研究が示すように，画像処理によるジェスチャ認識は高い精度を実現しているものの，これらをシュート種類の判別ロジックに使用する試みはなされていない．

そこで本研究では，従来の位置情報に基づく判別に加え，シュート時における審判のジェスチャ認識を新たな判断パラメータとして導入する手法を提案する． 本研究の目的は，先行研究\cite{stats}のアプローチに対して審判のジェスチャ情報を統合することで，シュート種類の判別精度がどの程度向上するかを明らかにすることである．具体的には，シュート位置による判別のみを用いた場合と，ジェスチャ認識による判別を組み合わせた場合とでシュート判別の検出率を比較検証し，シュート種類判別システムにおけるジェスチャ認識の有効性を検討する．

\chapter{審判のジェスチャを利用した\\シュート種類判別法}
\section{概要}
本節では，提案手法の処理概要について述べる．本手法の処理の流れを図3.1に示す．本手法は，バスケットボールのシュートシーンを撮影した動画データと，その動画内でシュートが放たれた瞬間のフレーム番号を入力とする．

本手法では，大きく分けて二つのアプローチによる判別処理が行われる． 第一に，入力動画全体に対して審判の検出および骨格認識を行い，そのジェスチャに基づいてシュートの種類を判別する処理である． 第二に，指定されたシュート瞬間のフレームに対し物体検出を行い選手を検出し，ホモグラフィ変換を用いて画像上の選手の座標をコート平面上の座標へ変換する．その後，シューターを人力で選択し，選択したシューターの変換後の位置情報に基づいたシュート種類の判別を行う処理である．

最終的な判別においては，これら二つの結果を統合する．基本的には選手の位置情報に基づく判別を行うが，オクルージョンや検出ミスにより位置特定が未検出となった場合に対し，審判のジェスチャ認識による結果を補完的に採用する．この統合処理を経て，最終的なシュート種別を出力する．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=1.0\linewidth]{image/system.pdf}
  
  \caption{処理の流れ}
  \label{fig:system}
\end{figure}

\section{物体検出}
本手法における映像内のオブジェクト検出および骨格認識には，Ultralytics社が開発したYOLO (You Only Look Once) \cite{detect} を用いる．YOLOは，高速かつ高精度なリアルタイム処理が可能なアルゴリズムであり，画像全体を一度の処理で解析することで，対象物の位置とクラスを同時に推定することが可能である．YOLOのデフォルトモデルによる実行例を図\ref{fig:yolo_default}に示す．

YOLOの大きな特徴として，あらかじめ用意された事前学習済みのデフォルトモデルを利用できるだけでなく，ユーザー独自のデータセットを用いて学習を行える点が挙げられる．具体的には，ユーザーが独自に用意した画像データに対してアノテーションを行い，それを機械学習させることで，特定の対象物を認識するオリジナルのモデルを作成することが可能である．

本手法ではこの機能を活用し，デフォルトのモデルに加えて，バスケットボールの試合映像において審判を正確に検出・分類するための専用モデルを構築し，利用している．

% 図3.2の挿入（画像のファイル名は適宜変更してください）
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.8em}
  % 画像ファイル名を指定
  \includegraphics[width=0.7\linewidth]{image/basketball.jpg}
  \caption{YOLOによる物体検出の実行例}
  \label{fig:yolo_default}
\end{figure}

\section{シューター位置による判別}
本手法では，審判のジェスチャ認識と並行して，画像処理を用いた選手の位置推定によるシュート種別の判別を行う．本節では，ホモグラフィ変換を用いた座標変換および判別アルゴリズムの詳細について述べる．

\subsection{ホモグラフィ変換行列の算出}
カメラで撮影された透視投影画像から，コートを真上から見た俯瞰図へ変換するために，ホモグラフィ変換を用いる．
まず，入力画像のフレーム内から，図\ref{fig:4points_select}に示すようにコート上のペイントエリアの四隅を手動で選択し，対応するコートの実際の寸法に基づく座標とのペアを作成する．これらの点対を用いて，OpenCVライブラリの \texttt{cv2.findHomography} 関数により，$3 \times 3$ のホモグラフィ変換行列 $\mathbf{H}$ を算出する．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % 画像ファイル名は実際のファイル名（例: image/select_points.pdf）に変更してください
  \includegraphics[width=0.8\linewidth]{image/4points_select.png}
  \caption{ホモグラフィ変換のための4点選択の様子}
  \label{fig:4points_select}
\end{figure}

\subsection{選手座標の推定とシュート判別}
前節で構築したYOLOモデル，あるいは汎用の物体検出モデルを用いて検出された選手のバウンディングボックス情報を利用し，以下の手順で判別を行う．

\begin{enumerate}
    \item \textbf{足元座標の取得}:
    検出された選手のバウンディングボックスの左上座標を $(x_1, y_1)$，右下座標を $(x_2, y_2)$ とする．このとき，選手がコートに接している位置（足元）の画像座標 $(u, v)$ を，バウンディングボックスの下辺中央として次式で定義する．
    \begin{equation}
        (u, v) = \left( \frac{x_1 + x_2}{2}, \ y_2 \right)
    \end{equation}

    \item \textbf{座標変換}:
    算出した行列 $\mathbf{H}$ を用いて，画像座標 $(u, v)$ をコート平面上の座標 $(x', y')$ へ変換する．変換式は以下の通りである．
    \begin{equation}
        \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} \sim \mathbf{H} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}
    \end{equation}

    \item \textbf{シューターの特定}:
    本手法では，画像内に複数の選手が存在する場合の誤判別を防ぐため，マウスイベントを用いたインタラクティブな選択手法を採用した．システム利用者が画像上の任意の選手をクリックすることで，その座標に対応する選手IDをシューターとして特定する．

    \item \textbf{シュート種別の判別}:
    特定されたシューターの変換後座標 $(x', y')$ が，3ポイントラインの内側（2点エリア）にあるか外側（3点エリア）にあるかを判別する．バスケットボールの3ポイントラインは，ゴールを中心とした円弧部分と，サイドラインに平行な直線部分（コーナー）から構成される．
    本手法では，コートパラメータとしてゴール中心座標 $(c_x, c_y)$，3ポイントラインの半径 $R$，コーナー直線のX座標範囲 $[x_{L}, x_{R}]$，および直線と円弧の接続点 $y_{int}$ を定義し，以下の条件分岐により判別を行う．

    \begin{itemize}
        \item \textbf{コーナーエリア ($y' \le y_{int}$) の場合}:
        ベースラインから接続点までの領域では，3ポイントラインは直線となる．したがって，シューターのX座標が直線の範囲内にあるかを判別する．
        \begin{equation}
            \text{Result} = 
            \begin{cases} 
                \text{IN (2pt)} & \text{if } x_{L} \le x' \le x_{R} \\
                \text{OUT (3pt)} & \text{otherwise}
            \end{cases}
        \end{equation}

        \item \textbf{トップエリア ($y' > y_{int}$) の場合}:
        接続点より奥の領域では，3ポイントラインは円弧となる．ゴール中心からのユークリッド距離の二乗 $d^2 = (x' - c_x)^2 + (y' - c_y)^2$ を計算し，半径の二乗 $R^2$ と比較する．
        \begin{equation}
            \text{Result} = 
            \begin{cases} 
                \text{IN (2pt)} & \text{if } d^2 \le R^2 \\
                \text{OUT (3pt)} & \text{otherwise}
            \end{cases}
        \end{equation}
    \end{itemize}
\end{enumerate}

この処理の実装結果として，変換後の位置を可視化した例を図\ref{fig:hom_court}に，判別結果を図\ref{fig:hom_select}に示す．
なお，図\ref{fig:hom_court}において，3ポイントラインの外側に位置する選手は赤色の円，内側に位置する選手は青色の円で表示されている．
また，図\ref{fig:hom_select}においては，選択した選手のバウンディングボックスが黄色く表示され，その上部に判別結果が表示されている．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % コート変換後の位置
  \includegraphics[width=0.5\linewidth]{image/hom_court.png}
  \caption{コート平面上への選手位置の投影結果}
  \label{fig:hom_court}
\end{figure}

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % 選択画面（判別結果が表示されているもの）
  \includegraphics[width=0.8\linewidth]{image/hom_select.png}
  \caption{選手選択および判別の実行例}
  \label{fig:hom_select}
\end{figure}


\section{審判の骨格認識}
本手法では，検出された審判のジェスチャ（腕の動作）に基づいてシュートの種類を判別するため，骨格認識（Pose Estimation）を行う．
骨格認識モデルには，物体検出と同様にYOLOシリーズの \texttt{yolov8x-pose} \cite{bone} を用いる．これは，YOLOの高精度な検出能力を維持しつつ，人物の姿勢推定を同時に行うことが可能なモデルである．

このモデルを用いることで，画像内の人物領域から「キーポイント」と呼ばれる関節の座標を取得することができる．取得可能なキーポイントは，鼻，目，耳，肩，肘，手首，腰，膝，足首の計17箇所であり，各点に対して画像上の座標 $(x, y)$ および検出の信頼度が算出される．
YOLOによって定義されるキーポイントのインデックスと対応する身体部位の一覧を図\ref{fig:pose_keypoints}に示す．

本研究では，これらのキーポイントのうち，特に上半身（肩，肘，手首）の座標位置関係に着目し，その形状パターンを解析することで審判のシグナルを識別する．
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}

  % --- 左側の画像 ---
  \begin{minipage}[b]{0.36\linewidth}
    \centering
    % 画像ファイル名を変更してください
    \includegraphics[width=\linewidth]{image/keypoints.png}
    % 必要であれば個別のキャプションを追加
    % \caption{キーポイント一覧}
  \end{minipage}
  \hfill
  % --- 右側の画像 ---
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    % 画像ファイル名を変更してください
    \includegraphics[width=\linewidth]{image/bone_player.jpg}
    % \caption{骨格認識の結果}
  \end{minipage}

  \caption{YOLOによる骨格認識のキーポイント一覧と実行例}
  \label{fig:pose_keypoints}
\end{figure}


\section{審判検出モデルの構築}
本手法では，バスケットボールの試合映像において審判を正確に認識するため，YOLOを用いた専用モデルのファインチューニングを行った．本節では，その学習に使用したデータセットおよび学習結果について述べる．

\subsection{データセットとアノテーション}
本手法の学習および評価に用いるデータセットとして，YouTube上で公開されている日本プロバスケットボールリーグ（Bリーグ）の試合映像2試合分 \cite{kawasaki,chiba} を利用した．

データセットの構築にあたり，映像内からシュート動作におけるジャンプ踏み切り直前の瞬間を「シュートのフレーム」と定義し，計254枚の静止画フレームを抽出した．また，各シュートに対し，その直前のパスからシュートが放たれた後，リバウンドを確保するかゴールが成功するまでの一連の区間を「シュートの動画」として同数切り出し，保存した．

審判検出モデルの学習には，前述の「シュートのフレーム」254枚を使用した．教師データの作成には，オープンソースの画像アノテーションツールであるLabelImg\cite{labelimg}を用いた．
アノテーション作業の例を図\ref{fig:annotation}に示す．同図において緑色の線で囲まれた領域が，手動で設定した審判のバウンディングボックスである．
このように画像内に存在する審判領域に対してアノテーションを行い，本研究の目的であるジェスチャ認識の主体となる「審判 (referee)」の1クラスのみを検出対象としてラベル情報をYOLO形式で出力した．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{image/annotation.png}
  \caption{アノテーション作業例}
  \label{fig:annotation}
\end{figure}

\subsection{学習結果}
作成したデータセットを用いてYOLOの学習を行った．その学習結果を図\ref{fig:training_results}に示す．
学習済みモデルの評価指標としてmAP (mean Average Precision) を用いた結果，mAP@0.5は19.5\% ，mAP@0.5:0.95は12.1\% であった．

一般的な物体検出タスクの基準と比較してこれらの値は低い水準に留まっているが，これは学習に用いたデータセットが254枚と非常に小規模であったことに起因すると考えられる．
しかしながら，本研究における物体検出の主目的は，後段の骨格認識処理のために審判の大まかな位置を特定することにある．
実際の検出結果を確認したところ，ジェスチャが未検出であったケースが一つもなかったため，本システムの目的においては許容できる精度であると判断した．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{image/yolo_results.png}
  \caption{学習結果}
  \label{fig:training_results}
\end{figure}

\section{ジェスチャ認識を用いた判別}
前節で述べた骨格認識によって得られたキーポイント情報を用い，最終的なシュート種類の自動判別を行う．

バスケットボールの競技規則において，3ポイントシュートの試投時には，審判は片手を頭上に挙げるジェスチャを行う（図\ref{fig:3gesture}）．一方，2ポイントシュートの場合，通常この動作は行われず，腕を下ろした状態である．本システムではこの差異に着目し，以下の手順で判別を行う．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\linewidth]{image/3pt.pdf}
  \caption{3ポイントのジェスチャ}
  \label{fig:3gesture}
\end{figure}


\subsection{判別条件の定義}
YOLOv8-poseによって取得される17点のキーポイントのうち，本手法では上半身の動作に関わる「肩 (Shoulder)」と「手首 (Wrist)」の座標を利用する．
画像座標系において，原点は画像の左上に位置し，鉛直下向きに $y$ 軸が定義される．したがって，画面上で「手が肩より上にある」状態は，手首の $y$ 座標の値が肩の $y$ 座標の値よりも小さい状態として数学的に定義できる．

具体的には，検出された任意の審判について，左手首の座標を $y_{lw}$，左肩の座標を $y_{ls}$，右手首の座標を $y_{rw}$，右肩の座標を $y_{rs}$ としたとき，以下の式(\ref{eq:judge_3pt})のいずれかが成立した場合に「3ポイントシュートのジェスチャ」であると判別する．

\begin{equation}
    y_{lw} < y_{ls} \quad \lor \quad y_{rw} < y_{rs}
    \label{eq:judge_3pt}
\end{equation}

\subsection{動画全体を通した判別フロー}
実際の試合映像では，審判が最大で3人存在する可能性があるため，本システムでは検出されたすべての審判（最大3人）を対象に判別を行う．
判別フローは以下の通りである．

\begin{enumerate}
    \item 対象となる「シュートの動画」の全フレームに対して処理を行う．
    \item 各フレームにおいて，検出された全ての審判について式(\ref{eq:judge_3pt})の条件を確認する．
    \item 動画内のいずれか1フレームでも，いずれかの審判において条件が満たされた場合，そのシュートを「3ポイントシュート」と判別する．実際に3ポイントシュートの条件を満たし判別が行われたフレームの例を図\ref{fig:3gesture}に示す．
    \item 動画の全フレームを通して一度も条件が満たされなかった場合，そのシュートを「2ポイントシュート」と判別する．条件を満たさず2ポイントシュートと判別されたフレームの例を図\ref{fig:2gesture}に示す．
\end{enumerate}

% --- 図の定義 ---
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  \includegraphics[width=0.75\linewidth]{image/3pt_ges.png}
  \caption{3ポイントと判別するフレーム（腕が挙がっている状態）}
  \label{fig:3gesture}
\end{figure}

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  \includegraphics[width=0.75\linewidth]{image/2pt_ges.png}
  \caption{2ポイントと判別するフレーム（腕が挙がっていない状態）}
  \label{fig:2gesture} 
\end{figure}

\section{統合手法を用いた判別}
本研究では，最終的なシュート種別の判別精度および判別可能率を向上させるため，前述した「シューター位置に基づく判別」と「審判ジェスチャに基づく判別」を組み合わせた統合手法を提案する．

シューターの足元位置をコート平面へ投影して判別する手法（以下，位置推定手法）は，3ポイントラインとの幾何学的な位置関係を直接計算するため，原理的な信頼性は高い．
しかし，選手同士の重なりやフレームアウトにより，シューターの検出や足元の特定に失敗し，判別不能（未検出）となる場合が存在する．
実際に，位置推定手法において検出に失敗した例を図\ref{fig:undetected}に示す．同図のような状況では，シューターの足元座標が取得できないため位置による判別は不可能となる．

一方で，審判のジェスチャに基づく判別（以下，ジェスチャ手法）は，シューターの位置検出に依存せずに判別が可能であるという利点を持つ．
そこで統合手法では，以下の優先順位に従って最終的な判別を出力する．

\begin{enumerate}
    \item まず，位置推定手法による判別を試みる．
    \item 位置推定手法により「2ポイント」または「3ポイント」と判別された場合，その結果を最終的な判別として採用する．
    \item 位置推定手法の結果が未検出であった場合に限り，代替手段としてジェスチャ手法の結果を採用する．
\end{enumerate}

このアルゴリズムにより，位置推定手法が高い精度で判別できるシーンではその正確さを活かしつつ，位置特定が困難なシーンにおいてはジェスチャ手法によって判別を補完する．

% --- 図の挿入 ---
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  \includegraphics[width=0.9\linewidth]{image/NG.jpg}
  \caption{位置推定手法において未検出となるフレームの例}
  \label{fig:undetected} % ← ラベル名を重複しないものに変更しました
\end{figure}

\chapter{評価}
\section{評価の目的}
本章では，第3章で提案したシュート種別自動判別システムの有効性を検証するために行った評価について述べる．

前章で述べた通り，シュートの位置に基づく判別手法は，原理的な信頼性は高いものの，オクルージョン等による未検出が発生するという課題があった．一方，審判のジェスチャ認識に基づく手法は，選手の位置に依存せずに判別可能であるが，映像解析上のノイズやほかのジェスチャなどを誤検出するリスクを含んでいる．

そこで本実験では，Bリーグのバスケットボール試合映像 \cite{kawasaki,chiba} を用いて，以下の3点について評価を行うことを目的とする．

\begin{enumerate}
    \item \textbf{位置推定手法の限界の確認}: 従来のアプローチである位置推定のみを用いた場合，どの程度の割合で未検出が発生するかを確認する．
    \item \textbf{ジェスチャ認識の精度の検証}: 審判の骨格情報を用いたジェスチャ認識が，実用的な精度で2ポイント/3ポイントを識別可能か検証する．
    \item \textbf{統合手法の有効性の実証}: 位置推定とジェスチャ認識を組み合わせた提案手法（統合手法）を用いることで，判別精度を維持しつつ，システム全体の判別可能率（カバー率）が向上することを明らかにする．
\end{enumerate}

\section{評価の方法}
本実験では，提案手法の有効性を検証するため，以下のデータセットおよび条件を用いて評価を行う．

\subsection{使用データセット}
評価には，前章で作成した計254本のシュート動画を用いる．
データセットの内訳は，2ポイントシュートが \textbf{131}本，3ポイントシュートが \textbf{123}本である．
これらの動画に対する正解ラベルは，筆者が実際の映像を目視で確認し，バスケットボールのルールに基づいて付与したものを使用する．

\subsection{比較対象とする手法}
各アプローチの特性と統合による効果を明らかにするため，以下の3つの手法についてそれぞれ評価を行う．

\begin{enumerate}
    \item \textbf{シュート位置による判別}:
    シューターの足元座標と3ポイントラインの幾何学的位置関係のみを用いて判別を行う．オクルージョン等により足元座標が取得できない場合は「未検出」として扱う．
    
    \item \textbf{ジェスチャ認識による判別}:
    審判の骨格認識（YOLOv8-pose）を用いて検出された腕の動作のみを用いて判別を行う．
    
    \item \textbf{統合手法による判別（提案手法）}:
    上記2つを組み合わせた手法である．基本的にはシュート位置による判別を優先し，位置推定において「未検出」となった場合に限り，ジェスチャ認識の結果を採用して判別を行う．
\end{enumerate}

\subsection{評価基準}
評価基準として，システムが出力した判別結果が，入力されたシュート動画の実際のアクションと一致するかを検証する．
本実験では，システムが出力した判別結果が正解ラベルと一致したものを「検出」とした．

これに基づき，全データに対する検出率および，誤検出率と未検出率を算出し，手法間の比較を行う．

\section{結果}
作成したデータセットに対する，シュート位置による判別，ジェスチャ認識による判別，およびそれらを組み合わせた統合手法による判別結果を表\ref{tab:result_comparison}に示す．

\begin{table}[htbp]
    \centering
    \caption{各手法による判別結果の比較}
    \label{tab:result_comparison}
    \resizebox{\columnwidth}{!}{
        \begin{tabular}{c|c|ccc}
            \hline \hline
            \textbf{判別の種類} & \textbf{シュートの種類} & \textbf{検出} & \textbf{未検出} & \textbf{誤検出} \\ \hline
            
            \multirow{2}{*}{\textbf{シューター位置}} & 2ポイント & 116 (89.23\%) & 14 (10.77\%) & 1 (0.77\%) \\ \cline{2-5}
             & 3ポイント & 113 (91.13\%) & 5 (4.03\%) & 4 (3.23\%) \\ \hline
            
             \multirow{2}{*}{\textbf{ジェスチャ}} & 2ポイント & 86 (66.15\%) & 0 (0.00\%) & 45 (34.62\%) \\ \cline{2-5}
             & 3ポイント & 110 (88.71\%) & 0 (0.00\%) & 13 (10.48\%) \\ \hline
            
            \multirow{2}{*}{\textbf{統合}} & 2ポイント & 127 (96.95\%) & 0 (0.00\%) & 4 (3.05\%) \\ \cline{2-5}
             & 3ポイント & 117 (95.12\%) & 0 (0.00\%) & 6 (4.88\%) \\ \hline \hline
        \end{tabular}
    }
\end{table}

まず，各単体手法の結果について述べる．
シュート位置による判別について，2ポイントシュートでは検出率が89.23\%，未検出率が10.77\%，誤検出率が0.77\%であり，3ポイントシュートでは検出率が91.13\%，未検出率が4.03\%，誤検出率が3.23\%であった．
一方，ジェスチャ認識による判別について，未検出は発生しなかった．また，2ポイントシュートでは検出率が66.15\%，誤検出率が34.62\%であり，3ポイントシュートでは検出率が88.71\%，誤検出率が10.48\%であった．

次に，提案する統合手法の結果について述べる．
統合手法では，2ポイントシュートの検出率が96.95\%，3ポイントシュートの検出率が95.12\%となった．
これは，シュート位置による判別単体の場合と比較して，2ポイントで約7.7ポイント，3ポイントで約4.0ポイントの向上である．
この値は，Versnikらの研究\cite{stats}と比較しても高い値である．
統合手法の判別結果がシュート位置による判別結果と比較し，ともに向上したことは，シュート位置による判別における未検出のケースを，ジェスチャ認識により効果的に補完しているといえる．

\section{考察}
本実験の結果より，ジェスチャ認識を用いた判別においては，3ポイントシュートの検出に関しては一定の成果が得られたものの，2ポイントシュートに対しては誤検出率が高い傾向が見られた．また，一部の3ポイントシュートにおいてもジェスチャ認識に失敗する事例が確認された．
本節では，これらの要因について「判別アルゴリズムの特性」および「画像認識プロセスにおける技術的課題」の二つの観点から詳細に考察する．

\subsection{判別アルゴリズムと誤検出の要因}
本来は2ポイントであるにも関わらず，誤って3ポイントと判別されたことによる2ポイントシュートの誤検出率が高くなった最大の要因は，本手法で採用した判別ロジックの単純性と，バスケットボール競技特有の審判動作の多様性にあると考えられる．

本研究におけるジェスチャ判別は，骨格推定によって得られた「手首」と「肩」の$y$座標を比較し，手首が肩よりも上位にあるか否かという条件のみに基づいている．
しかし，実際のバスケットボールの試合において，審判が腕を肩より上に挙げる動作は3ポイントシュートの試投に限られない．例えば，ファウルの宣告，反則の発生によるクロックの停止，タイムアウトの合図，選手交代の許可，あるいはスローインの方向指示など，試合運営上の多くの局面で挙手動作が行われる．
片腕または両腕の垂直挙上によって表す3ポイントシュートのジェスチャは，これらの他のシグナルと形状的に類似しており，手と肩の位置関係のみを用いた単純な閾値処理では，これらを明確に識別することは困難である．
このような誤検出を根本的に抑制するためには，単なる姿勢推定だけでなく，試合状況を考慮し，その場面がシュートに関連する局面であるかを識別するシーン認識技術の実装が不可欠である．

\subsection{物体検出および骨格推定の精度に起因する課題}
次に，3ポイントシュートであるにも関わらずジェスチャ認識に失敗し，誤検出となったケースについて，その技術的な要因を考察する．

第一の要因として，物体検出におけるバウンディングボックスの領域欠損が挙げられる．
作成した審判検出モデルは，主に直立あるいは走行中の審判を学習データとして構築されている．しかし，審判が3ポイントシュートの合図として腕を高く真上に伸ばした際，推論されたバウンディングボックスが審判の頭頂部付近までしかカバーできず，最も重要な特徴量である「手首から先の領域」が枠外にはみ出してしまう現象が散見された．検出領域内に手首が存在しない場合，後段の骨格推定モデルは手首座標を正しく算出できないため，結果としてジェスチャの条件を満たさず，認識失敗に繋がったと考えられる．

第二の要因として，カメラアングルおよびオクルージョン（遮蔽）の影響が挙げられる．
本実験で使用した映像は一般的な中継アングルであり，審判が常にカメラに対して正対しているわけではない．審判がカメラに背を向けている場合や，選手と重なっている場合，あるいは画面の端で見切れている場合においては，骨格推定モデルによるキーポイント抽出の信頼度が著しく低下する傾向が見られた．特に，腕が体幹と重なって見えるアングルでは，手首の位置を正確に特定できず，誤った座標が出力されることで判別ミスを誘発した可能性が高い．

以上のことから，ジェスチャ認識の精度向上には，単にモデルの認識能力を高めるだけでなく，腕を挙げた状態を十分に含む多様な学習データの拡充や，バウンディングボックスのサイズ調整といった処理の改善が不可欠であると結論付けられる．
\chapter{まとめ}

\section{まとめ}

本研究では，バスケットボールの試合映像を用いたスタッツ自動収集の実現に向け，従来の選手位置情報のみに依存した判別手法が抱える課題を解決するために，審判のジェスチャ認識を統合した新たなシュート種類判別システムを提案した．

従来のホモグラフィ変換を用いた位置推定手法は，原理的な信頼性は高いものの，オクルージョンや検出漏れによって未検出となるケースが存在した．これに対し，本研究ではバスケットボールの競技規則に着目し，審判が提示するハンドジェスチャ骨格認識モデルを用いて認識することで，シュート種類の判別を補完するアプローチを試みた．

Bリーグの試合映像を用いた評価実験の結果，以下の知見が得られた．
第一に，位置推定手法単体では，オクルージョン等により2ポイントシュートの約10.8\%が未検出となった一方で，提案する統合手法を用いることで，これらを効果的に補完できることが確認された．
第二に，統合手法による判別結果は，2ポイントシュートで96.95\%，3ポイントシュートで95.12\%の検出率を達成した．これは位置推定単体と比較して，それぞれ約7.7ポイント，4.0ポイントの向上であり，提案手法の有効性が定量的に示されたといえる．
以上の結果より，審判のジェスチャ情報は，映像解析によるシュート判別において極めて有用な特徴量であり，位置情報と統合することでシステムの検出率を大幅に向上させることが可能であると結論付けられる．

本研究では統合手法の有効性を示したが，実用的な自動スタッツ収集システムの構築に向けては，いくつかの課題が残されている．今後の課題として，以下の3点が挙げられる．

第一に，シュート動画の自動抽出である．
本実験では，元動画より手動でシュートシーンを切り出しているが，システムの実用化には，試合全体の映像からシュートが行われたフレーム範囲を特定し，自動的に動画を生成する機能が不可欠である．これには，ボールの軌道認識や選手の行動認識技術を応用し，一連のシュート動作の開始と終了を自動的に判別するアルゴリズムの実装が必要である．

第二に，ホモグラフィ変換行列の算出に用いる特徴点の自動検出である．
現状では，ホモグラフィ変換のための対応点を手動で設定している．しかし，カメラアングルが頻繁に変化する実際の放送映像へ適用するためには，この過程の自動化が求められる．コート内のペイントエリア領域やラインをセグメンテーション技術等を用いて認識し，フレームごとにホモグラフィ変換行列を更新する手法の検討が必要である．

第三に，2ポイントシュート判別における誤検出への対応である．
第4章の考察で述べた通り，3ポイントシュートのジェスチャは単純な動作であるため，ファウルやタイムアウトなどの他のシグナルと誤認しやすいという課題がある．この解決に対しては，静的な姿勢情報だけでなく，動作の時系列変化を考慮した認識手法の導入を検討する．具体的には，Wangらの研究\cite{wang}で提案されている時空間特徴を用いた手法等を参考にし，紛らわしい動作と正規のジェスチャを高精度に分離するモデルの構築を目指す．

\acknowledgement %謝辞

北村泰彦教授には、私が他研究室の所属であることを顧みず、快く研究室の一員として受け入れていただきました。ゼミへの参加をご快諾いただき、所属学生と分け隔てなく熱心にご指導いただいたことは、本研究の遂行において不可欠でした。先生の寛大なご配慮と温かいご指導に、心より御礼申し上げます。

山本倫也教授には，学期途中での研究室変更という事態に際しましても，多大なるご配慮と柔軟なご対応をいただきました．また，それに伴う研究テーマの変更につきましても，有益なご助言と温かいご指導を賜りましたこと，この場を借りて深く感謝申し上げます．

北村研究室の同輩諸氏には，
日頃から多くのご助言やご支援をいただき，大変感謝しています．

また，山本研究室の同輩諸氏には，
特に審査前において多くのご助言やご支援をいただき，大変感謝しています．

最後に，4年間大学に通わせてくれた祖父母に，心から感謝しています．

\bibliographystyle{junsrt}
\bibliography{sample} 

\end{document}