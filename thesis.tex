% Last updated at 2024/12/10 09:39:36
\documentclass[12pt,a4j]{ltjsreport}
\usepackage{ltklthesis}
\usepackage{multirow}
\usepackage{float}
\usepackage{amsmath}

\begin{document}

\type{B} %卒論はB，修論はM
\author{山形隼士}
\id{2503} %学籍番号
\fyear{2025} %修了・卒業年(修了・卒業式が2025年3月なら2025)
\title{審判ジェスチャに着目した\\バスケットボールシュート種類\\判別手法}
\abstract{
こんにちは，アブストラクトです
}

\maketitle

\chapter{はじめに}
近年，スポーツアナリティクスの分野は著しい発展を遂げており，バスケットボール競技においても，各選手のパフォーマンスを詳細に表すスタッツと呼ばれるデータを用いた戦術分析や選手評価が一般化している．これらの指標は，シュート成功率，リバウンド数，アシスト数などの定量的データに基づいており，チームの勝利に直結する重要な要素となる．

一方で，現状のスタッツ収集は主に人力で行われている点や，収集に用いるアプリケーションが競技カテゴリごとに異なり統一されていないなどの課題がある．そのため，スタッツ収集のプロセスを自動化する必要性が高まっている．

この点に関して，Versnikら\cite{stats}は試合映像を入力とし，物体検出や追跡技術を用いてスタッツを自動生成するシステムを提案している．しかし，映像内の選手位置情報のみから，2ポイントシュートか3ポイントシュートかというシュートの種類を判定する手法には技術的な限界が存在する．具体的には，足元の位置検出における微小な誤差や，カメラアングルによる射影変換の歪み，あるいはディフェンス選手によるオクルージョンが発生し，物体検出での未検出が起こった場合，3ポイントライン際での判定精度が著しく低下するという課題がある．

この課題に対し，本研究では審判の情報に着目する．バスケットボールの審判は，シュートが放たれた際，その放たれた位置や状況に応じて，2ポイントあるいは3ポイントを示す特定のハンドジェスチャを行う規定がある．すなわち，審判の動作は，シュートの種類を決定づける信頼性の高い視覚情報であると言える．

以上の背景から，本研究では，従来の選手位置座標のみに依存した判定手法に加え，シュート時における審判のジェスチャ認識を導入した新たな統合判別手法を提案する．審判のジェスチャを統合することで，上記のような判定困難な状況において，シュート種類の判別精度がどの程度改善されるかを検証し，その有効性を明らかにする．

本論文は全5章で構成する．第2章では，関連研究と本研究の目的について述べる．第3章では，本研究で提案するシュート種類の判別手法の詳細を述べる．第4章では，評価と結果について述べる．第5章では，本研究のまとめについて述べる．

\chapter{コンピュータビジョンを用いた\\バスケットボールの研究} 

\section{バスケットボール競技}
バスケットボールは，1チーム5名のプレイヤーからなる2つのチームが，コートの両端に設置されたリング（バスケット）へボールを投じ，その通過数によって得点を競う球技である ．コート上には計10名の選手が存在し，攻守を激しく入れ替えながら試合が展開される ．

攻撃側の選手がリングに向けてボールを投じる動作を「シュート」と呼び，その動作を行う選手を「シューター」と呼ぶ ．得点の種類はシュートが放たれた位置によって厳密に区分されており，その基準となるのがゴールの中心から6.75m離れた位置に描かれた「3ポイントライン」である ．図1にバスケットボールのコート図を示す ．このラインを境界として，ラインの内側（2ポイントエリア）から放たれたシュートは「2ポイントシュート」，外側（3ポイントエリア）から放たれたシュートは「3ポイントシュート」と定義される ．
\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=0.8\linewidth]{image/court.pdf}
  
  \caption{バスケットボールコートの図}
  \label{fig:basketball_court}
\end{figure}

試合の判定および進行管理は，最大3名の審判員（レフェリー）によって行われる ．審判は，ファウルやバイオレーションなどの反則行為に対する判定だけでなく，試合中に発生するあらゆる事象に対して規定のハンドジェスチャを用いて視覚的に伝達を行う役割を担う ．特に，本研究で着目するシュート動作に関しては，シュートが放たれた瞬間にその試行が2ポイントであるか3ポイントであるかを明確にするため，審判はそれぞれに対応した異なるジェスチャを提示する規定となっている ．図2にシュートにおける審判のジェスチャを示す ．

\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}
  % 高さを揃えるために共通の高さを指定
  \newlength{\imgheight}
  \setlength{\imgheight}{4.0cm} % ← 縮小 (もともと4cm)
  
  % --- 左側の画像 ---
  \begin{minipage}[t]{0.30\linewidth} 
    \centering
    \raisebox{3mm}{\includegraphics[height=\imgheight]{image/2pt.pdf}}
  \end{minipage}
  \hspace{0.5em} % ← 画像の間隔を微調整
  % --- 右側の画像 ---
  \begin{minipage}[t]{0.30\linewidth}
    \centering
    \includegraphics[height=\imgheight]{image/3pt.pdf}
    % \label{fig:3pt} % 同上
  \end{minipage}
  
  \caption{2ポイントシュート（左）および3ポイントシュート（右）のジェスチャ}
  \label{fig:shoot_gesture}
\end{figure}


また，現代のバスケットボール競技においては，試合の勝敗だけでなく，各選手の貢献度やパフォーマンスを詳細に可視化するために「スタッツ（Stats）」と呼ばれるデータが重要視されている．スタッツとは，その選手が何本シュートを決めたか，何回反則を犯したかなどの詳細なプレイ記録の総称である ．図2.3にスタッツの例を示す．表中の数値は選手の成績を表しており，例えば図中の「MIN」の個所は出場時間，「A（Attempted）」の箇所はシュートを打った数，「M（Made）」の箇所はシュートを決めた数を示している ．現状，これらのスタッツ収集は，専門の記録員がシステムを用いて行っており，依然として人の目視による判断と手動入力に依存している．

\begin{figure}[htbp]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=1.0\linewidth]{image/stats.pdf}
  
  \caption{スタッツの例}
  \label{fig:stats}
\end{figure}

\section{関連研究}
本節では，バスケットボールにおけるスタッツの自動収集および審判のジェスチャ認識に関する既存研究を概観し，それぞれの提案手法の詳細と，本研究の立場から見た課題（欠点）について述べる．

\subsection{スタッツの自動収集}
VeršnikとŠajn（2023）は，NBAの放送映像を入力とし，ディープラーニングを用いて選手やボールを検出し，試合の統計データ（スタッツ）を自動的に収集するシステムを提案している\cite{stats}． 彼らの手法では，まず物体検出アルゴリズムであるYOLOを用いて選手を検出し，追跡アルゴリズムであるDeepSORTと組み合わせることで各選手のトラッキングを行っている．さらに，DeepSORT単体では選手同士が交差した際などにIDが入れ替わりチーム分類を誤る問題があったため，MobileNetV2を用いた画像分類モデルを追加で導入し，チーム分類の精度を99.41\%まで向上させた。 シュート判定においては，ホモグラフィ変換を用いて映像内の3次元座標をコートの2次元平面座標へ変換し，ボールとゴールの位置関係および選手の足元の位置に基づいて，3ポイント，2ポイント，フリースローの判定を行っている．

しかしながら，本手法にはシュート判別の精度が低いという重大な課題がある．彼らの実験結果によると，シュート試投数の検出精度は高いものの，シュート成功（の判定や種別の分類において誤検出が目立った．具体的には，3ポイントシュートの成功検出精度は53.4\%に留まり，試投の検出精度も63.3\%であった．この精度の低さは，主にホモグラフィ変換の不安定さに起因している．特にコートの片側における変換行列の計算誤差が大きく，フリースローの場面において，選手の位置が3ポイントラインの外側であると誤って計算され，3ポイントシュートとして誤分類される事例が多発したことが報告されている．このように，画像座標から物理座標への変換に依存したシュート判定は，カメラアングルの変化やオクルージョンに対して脆弱であり，実用的なスタッツ収集には不十分である．

\subsection{HOG，LBP特徴量とSVMによる審判ジェスチャ認識}
Žemgulysら（2020）は，コンピュータビジョンを用いてバスケットボールの試合映像から審判のジェスチャを認識する手法を提案している\cite{wang}．彼らは，スポーツ映像のようなノイズの多い実環境下での認識を実現するため，画像の前処理としてRGB画像をグレースケール化し，Sobelフィルタを用いてエッジ検出を行うことで，照明変動の影響を軽減している．特徴量抽出には，形状情報を捉えるHOGと，テクスチャ情報を捉えるLBPの2種類を採用し，これらをSVMおよびランダムフォレストで分類する実験を行った．実験の結果，LBP特徴量とSVMを組み合わせたモデルが最も高い性能を示し，全クラス平均で95.6\%の認識精度を達成した．特に3ポイントシュート成功のジェスチャに関しては，正面からの映像で97.7\%という極めて高い精度で認識できている．

しかしながら，この研究の課題は，認識したジェスチャをスタッツの自動集計やシュート判定の結果確定に活用していない点にある．本研究の主眼は，あくまで審判と記録員間のコミュニケーションミスを減らすためのジェスチャの認識そのものに置かれている．そのため，認識された3ポイント成功のジェスチャが，実際の得点加算処理や，Veršnikらの研究で課題とされたようなシュートが本当に入ったかどうかの判定の補正に利用されるシステム構成にはなっていない．単独のジェスチャ認識に留まっており，試合のコンテキストと統合されたスタッツ生成システムとしては機能していない．

\subsection{マルチスケール時空間特徴を用いた深層学習による審判ジェスチャ認識}
Wangら（2024）は，マルチスケールの時空間特徴を活用し，複雑なバスケットボールのシーンにおいて審判のジェスチャをリアルタイムで認識するシステムを提案している\cite{zemgulys}．
彼らは「GIS-ResT」と呼ばれる軽量なネットワークモデルを構築した．これは，時間領域のマルチスケール時空間畳み込みモジュールと，大域的な情報を同期させるためのチャネル注意機構を組み合わせたものである．
このモデルは，従来の3D畳み込みと比較して計算コストを大幅に削減しつつ，ジェスチャの詳細な特徴を捉えることに成功しており，平均認識率は92.20\%に達している．また，このシステムはモバイル端末やWebページ上での動作を想定して実装されており，選手や観客などユーザーに対して認識したジェスチャの種類を音声でブロードキャストする機能を有している。

この研究もまた，スタッツの収集やシュート判定のロジックにジェスチャを利用していない点が課題である．本システムの目的は，聴覚や視覚に障害を持つ観客への支援や，記録員が見逃した判定の確認，あるいはコーチや選手がビデオ分析を行う際の該当シーンの検索補助に限定されている．システムはジェスチャを分類して提示する補助機能として設計されており，例えば，審判が2点のジェスチャをしたから，自動的にスコアに2点を加算するといった，スタッツ管理の自動化に直結する機能は実装されていない．

\section{研究の目的}
前節で述べたように，Veršnikら\cite{stats}による先行研究では，ホモグラフィ変換を用いて映像内の座標をコート平面上の座標へ変換し，その位置情報に基づいてシュート種別の判定を行っていた．しかし，この手法はカメラアングルやレンズの歪みの影響を受けやすく，特にコートの奥側や端部において変換行列の計算誤差が増大するという欠点を抱えていた．その結果，本来はフリースローである事象を3ポイントシュートとして誤認識するなど，シュート種類の判別精度が低下する課題が未解決のまま残されている．

一方で，バスケットボールの競技規則において，審判は3ポイントシュートの試投時および成功時に，2ポイントシュートは成功時のみに，その種類を特定するための明確なジェスチャを行うことが義務付けられている．Žemgulysら\cite{wang}やWangら\cite{zemgulys}の研究が示すように，画像処理によるジェスチャ認識は高い精度を実現しているものの，これらをシュート種類の判別ロジックに使用する試みはなされていない．

そこで本研究では，従来の位置情報に基づく判定に加え，シュート時における審判のジェスチャ認識を新たな判断パラメータとして導入する手法を提案する． 本研究の目的は，先行研究\cite{stats}のアプローチに対して審判のジェスチャ情報を統合することで，シュート種類の判別精度がどの程度向上するかを明らかにすることである．具体的には，シュート位置による判別のみを用いた場合と，ジェスチャ認識による判別を組み合わせた場合とでシュート判別の検出率を比較検証し，シュート種類判別システムにおけるジェスチャ認識の有効性を検討する．

\chapter{審判のジェスチャを利用した\\シュート種類判別法}
\section{概要}
本節では，提案手法の処理概要について述べる．本手法の処理の流れを図3.1に示す．本手法は，バスケットボールのシュートシーンを撮影した動画データと，その動画内でシュートが放たれた瞬間のフレーム番号を入力とする．

本手法では，大きく分けて二つのアプローチによる判定処理が行われる． 第一に，入力動画全体に対して審判の検出および骨格認識を行い，そのジェスチャに基づいてシュートの種類を判別する処理である． 第二に，指定されたシュート瞬間のフレームに対し物体検出を行い選手を検出し，ホモグラフィ変換を用いて画像上の選手の座標をコート平面上の座標へ変換する．その後，シューターを人力で選択し，選択したシューターの変換後の位置情報に基づいたシュート種類の判別を行う処理である．

最終的な判定においては，これら二つの結果を統合する．基本的には選手の位置情報に基づく判定を行うが，オクルージョンや検出ミスにより位置特定が未検出となった場合に対し，審判のジェスチャ認識による結果を補完的に採用する．この統合処理を経て，最終的なシュート種別を出力する．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.7em}

  % 画像ファイルの幅を、本文の幅の80%に設定（数字を変えて調整可能）
  \includegraphics[width=1.0\linewidth]{image/system.pdf}
  
  \caption{処理の流れ}
  \label{fig:system}
\end{figure}

\section{物体検出}
本手法における映像内のオブジェクト検出および骨格認識には，Ultralytics社が開発したYOLO (You Only Look Once) \cite{detect} を用いる．YOLOは，高速かつ高精度なリアルタイム処理が可能なアルゴリズムであり，画像全体を一度の処理で解析することで，対象物の位置とクラスを同時に推定することが可能である．YOLOのデフォルトモデルによる実行例を図\ref{fig:yolo_default}に示す．

YOLOの大きな特徴として，あらかじめ用意された事前学習済みのデフォルトモデルを利用できるだけでなく，ユーザー独自のデータセットを用いて学習を行える点が挙げられる．具体的には，ユーザーが独自に用意した画像データに対してアノテーションを行い，それを機械学習させることで，特定の対象物を認識するオリジナルのモデルを作成することが可能である．

本手法ではこの機能を活用し，デフォルトのモデルに加えて，バスケットボールの試合映像において審判を正確に検出・分類するための専用モデルを構築し，利用している．

% 図3.2の挿入（画像のファイル名は適宜変更してください）
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.8em}
  % 画像ファイル名を指定
  \includegraphics[width=0.7\linewidth]{image/basketball.jpg}
  \caption{YOLOによる物体検出の実行例}
  \label{fig:yolo_default}
\end{figure}

\section{シューター位置による判定}
本手法では，審判のジェスチャ認識と並行して，画像処理を用いた選手の位置推定によるシュート種別の判定を行う．本節では，ホモグラフィ変換を用いた座標変換および判定アルゴリズムの詳細について述べる．

\subsection{ホモグラフィ変換行列の算出}
カメラで撮影された透視投影画像から，コートを真上から見た俯瞰図へ変換するために，ホモグラフィ変換を用いる．
まず，入力画像のフレーム内から，図\ref{fig:4points_select}に示すようにコート上のペイントエリアの四隅を手動で選択し，対応するコートの実際の寸法に基づく座標とのペアを作成する．これらの点対を用いて，OpenCVライブラリの \texttt{cv2.findHomography} 関数により，$3 \times 3$ のホモグラフィ変換行列 $\mathbf{H}$ を算出する．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % 画像ファイル名は実際のファイル名（例: image/select_points.pdf）に変更してください
  \includegraphics[width=0.8\linewidth]{image/4points_select.png}
  \caption{ホモグラフィ変換のための4点選択の様子}
  \label{fig:4points_select}
\end{figure}

\subsection{選手座標の推定とシュート判定}
前節で構築したYOLOモデル，あるいは汎用の物体検出モデルを用いて検出された選手のバウンディングボックス情報を利用し，以下の手順で判定を行う．

\begin{enumerate}
    \item \textbf{足元座標の取得}:
    検出された選手のバウンディングボックスの左上座標を $(x_1, y_1)$，右下座標を $(x_2, y_2)$ とする．このとき，選手がコートに接している位置（足元）の画像座標 $(u, v)$ を，バウンディングボックスの下辺中央として次式で定義する．
    \begin{equation}
        (u, v) = \left( \frac{x_1 + x_2}{2}, \ y_2 \right)
    \end{equation}

    \item \textbf{座標変換}:
    算出した行列 $\mathbf{H}$ を用いて，画像座標 $(u, v)$ をコート平面上の座標 $(x', y')$ へ変換する．変換式は以下の通りである．
    \begin{equation}
        \begin{bmatrix} x' \\ y' \\ 1 \end{bmatrix} \sim \mathbf{H} \begin{bmatrix} u \\ v \\ 1 \end{bmatrix}
    \end{equation}

    \item \textbf{シューターの特定}:
    本手法では，画像内に複数の選手が存在する場合の誤判定を防ぐため，マウスイベントを用いたインタラクティブな選択手法を採用した．システム利用者が画像上の任意の選手をクリックすることで，その座標に対応する選手IDをシューターとして特定する．

    \item \textbf{シュート種別の判定}:
    特定されたシューターの変換後座標 $(x', y')$ が，3ポイントラインの内側（2点エリア）にあるか外側（3点エリア）にあるかを判定する．バスケットボールの3ポイントラインは，ゴールを中心とした円弧部分と，サイドラインに平行な直線部分（コーナー）から構成される．
    本手法では，コートパラメータとしてゴール中心座標 $(c_x, c_y)$，3ポイントラインの半径 $R$，コーナー直線のX座標範囲 $[x_{L}, x_{R}]$，および直線と円弧の接続点 $y_{int}$ を定義し，以下の条件分岐により判定を行う．

    \begin{itemize}
        \item \textbf{コーナーエリア ($y' \le y_{int}$) の場合}:
        ベースラインから接続点までの領域では，3ポイントラインは直線となる．したがって，シューターのX座標が直線の範囲内にあるかを判定する．
        \begin{equation}
            \text{Result} = 
            \begin{cases} 
                \text{IN (2pt)} & \text{if } x_{L} \le x' \le x_{R} \\
                \text{OUT (3pt)} & \text{otherwise}
            \end{cases}
        \end{equation}

        \item \textbf{トップエリア ($y' > y_{int}$) の場合}:
        接続点より奥の領域では，3ポイントラインは円弧となる．ゴール中心からのユークリッド距離の二乗 $d^2 = (x' - c_x)^2 + (y' - c_y)^2$ を計算し，半径の二乗 $R^2$ と比較する．
        \begin{equation}
            \text{Result} = 
            \begin{cases} 
                \text{IN (2pt)} & \text{if } d^2 \le R^2 \\
                \text{OUT (3pt)} & \text{otherwise}
            \end{cases}
        \end{equation}
    \end{itemize}
\end{enumerate}

この処理の実装結果として，変換後の位置を可視化した例を図\ref{fig:hom_court}に，判定結果を図\ref{fig:hom_select}に示す．
なお，図\ref{fig:hom_court}において，3ポイントラインの外側に位置する選手は赤色の円，内側に位置する選手は青色の円で表示されている．
また，図\ref{fig:hom_select}においては，選択した選手のバウンディングボックスが黄色く表示され，その上部に判定結果が表示されている．

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % コート変換後の位置
  \includegraphics[width=0.5\linewidth]{image/hom_court.png}
  \caption{コート平面上への選手位置の投影結果}
  \label{fig:hom_court}
\end{figure}

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  % 選択画面（判定結果が表示されているもの）
  \includegraphics[width=0.8\linewidth]{image/hom_select.png}
  \caption{選手選択および判別の実行例}
  \label{fig:hom_select}
\end{figure}


\section{審判の骨格認識}
本手法では，検出された審判のジェスチャ（腕の動作）に基づいてシュートの種類を判別するため，骨格認識（Pose Estimation）を行う．
骨格認識モデルには，物体検出と同様にYOLOシリーズの \texttt{yolov8x-pose} \cite{bone} を用いる．これは，YOLOの高精度な検出能力を維持しつつ，人物の姿勢推定を同時に行うことが可能なモデルである．

このモデルを用いることで，画像内の人物領域から「キーポイント」と呼ばれる関節の座標を取得することができる．取得可能なキーポイントは，鼻，目，耳，肩，肘，手首，腰，膝，足首の計17箇所であり，各点に対して画像上の座標 $(x, y)$ および検出の信頼度が算出される．
YOLOによって定義されるキーポイントのインデックスと対応する身体部位の一覧を図\ref{fig:pose_keypoints}に示す．

本研究では，これらのキーポイントのうち，特に上半身（肩，肘，手首）の座標位置関係に着目し，その形状パターンを解析することで審判のシグナルを識別する．
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}

  % --- 左側の画像 ---
  \begin{minipage}[b]{0.36\linewidth}
    \centering
    % 画像ファイル名を変更してください
    \includegraphics[width=\linewidth]{image/keypoints.png}
    % 必要であれば個別のキャプションを追加
    % \caption{キーポイント一覧}
  \end{minipage}
  \hfill
  % --- 右側の画像 ---
  \begin{minipage}[b]{0.5\linewidth}
    \centering
    % 画像ファイル名を変更してください
    \includegraphics[width=\linewidth]{image/bone_player.jpg}
    % \caption{骨格認識の結果}
  \end{minipage}

  \caption{YOLOによる骨格認識のキーポイント一覧と実行例}
  \label{fig:pose_keypoints}
\end{figure}


\section{審判検出モデルの構築}
本手法では，バスケットボールの試合映像において審判を正確に認識するため，YOLOを用いた専用モデルのファインチューニングを行った．本節では，その学習に使用したデータセットおよび学習結果について述べる．

\subsection{データセットとアノテーション}
本手法の学習および評価に用いるデータセットとして，YouTube上で公開されているプロバスケットボールリーグ（Bリーグ）の試合映像2試合分 \cite{kawasaki,chiba} を利用した．

データセットの構築にあたり，映像内からシュート動作におけるジャンプ踏み切り直前の瞬間を「シュートのフレーム」と定義し，計254枚の静止画フレームを抽出した．また，各シュートに対し，その直前のパスからシュートが放たれた後，リバウンドを確保するかゴールが成功するまでの一連の区間を「シュートの動画」として同数切り出し，保存した．

審判検出モデルの学習には，前述の「シュートのフレーム」254枚を使用した．教師データの作成には，オープンソースの画像アノテーションツールであるLabelImg\cite{labelimg}を用いた．
アノテーション作業の例を図\ref{fig:annotation}に示す．同図において緑色の線で囲まれた領域が，手動で設定した審判のバウンディングボックスである．
このように画像内に存在する審判領域に対してアノテーションを行い，本研究の目的であるジェスチャ認識の主体となる「審判 (referee)」の1クラスのみを検出対象としてラベル情報をYOLO形式で出力した．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{image/annotation.png}
  \caption{アノテーション作業例}
  \label{fig:annotation}
\end{figure}

\subsection{学習結果}
作成したデータセットを用いてYOLOの学習を行った．その学習結果を図\ref{fig:training_results}に示す．
学習済みモデルの評価指標としてmAP (mean Average Precision) を用いた結果，mAP@0.5は19.5\% ，mAP@0.5:0.95は12.1\% であった．

一般的な物体検出タスクの基準と比較してこれらの値は低い水準に留まっているが，これは学習に用いたデータセットが254枚と非常に小規模であったことに起因すると考えられる．
しかしながら，本研究における物体検出の主目的は，後段の骨格認識処理のために審判の大まかな位置を特定することにある．
実際の検出結果を確認したところ，ジェスチャが未検出であったケースが一つもなかったため，本システムの目的においては許容できる精度であると判断した．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{image/yolo_results.png}
  \caption{学習結果}
  \label{fig:training_results}
\end{figure}

\section{ジェスチャ認識を用いた判別}
前節で述べた骨格認識によって得られたキーポイント情報を用い，最終的なシュート種類の自動判別を行う．

バスケットボールの競技規則において，3ポイントシュートの試投時には，審判は片手を頭上に挙げるジェスチャを行う（図\ref{fig:3gesture}）．一方，2ポイントシュートの場合，通常この動作は行われず，腕を下ろした状態である．本システムではこの差異に着目し，以下の手順で判定を行う．

\begin{figure}[H]
  \centering
  \includegraphics[width=0.4\linewidth]{image/3pt.pdf}
  \caption{3ポイントのジェスチャ}
  \label{fig:3gesture}
\end{figure}


\subsection{判定条件の定義}
YOLOv8-poseによって取得される17点のキーポイントのうち，本手法では上半身の動作に関わる「肩 (Shoulder)」と「手首 (Wrist)」の座標を利用する．
画像座標系において，原点は画像の左上に位置し，鉛直下向きに $y$ 軸が定義される．したがって，画面上で「手が肩より上にある」状態は，手首の $y$ 座標の値が肩の $y$ 座標の値よりも小さい状態として数学的に定義できる．

具体的には，検出された任意の審判について，左手首の座標を $y_{lw}$，左肩の座標を $y_{ls}$，右手首の座標を $y_{rw}$，右肩の座標を $y_{rs}$ としたとき，以下の式(\ref{eq:judge_3pt})のいずれかが成立した場合に「3ポイントシュートのジェスチャ」であると判定する．

\begin{equation}
    y_{lw} < y_{ls} \quad \lor \quad y_{rw} < y_{rs}
    \label{eq:judge_3pt}
\end{equation}

\subsection{動画全体を通した判定フロー}
実際の試合映像では，審判が最大で3人存在する可能性があるため，本システムでは検出されたすべての審判（最大3人）を対象に判定を行う．
判定フローは以下の通りである．

\begin{enumerate}
    \item 対象となる「シュートの動画」の全フレームに対して処理を行う．
    \item 各フレームにおいて，検出された全ての審判について式(\ref{eq:judge_3pt})の条件を確認する．
    \item 動画内のいずれか1フレームでも，いずれかの審判において条件が満たされた場合，そのシュートを「3ポイントシュート」と判別する．実際に3ポイントシュートの条件を満たし判定が行われたフレームの例を図\ref{fig:3gesture}に示す．
    \item 動画の全フレームを通して一度も条件が満たされなかった場合，そのシュートを「2ポイントシュート」と判別する．条件を満たさず2ポイントシュートと判定されたフレームの例を図\ref{fig:2gesture}に示す．
\end{enumerate}

% --- 図の定義 ---
\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  \includegraphics[width=0.75\linewidth]{image/3pt_ges.png}
  \caption{3ポイントと判別するフレーム（腕が挙がっている状態）}
  \label{fig:3gesture}
\end{figure}

\begin{figure}[H]
  \centering
  \setlength{\belowcaptionskip}{-0.5em}
  \includegraphics[width=0.75\linewidth]{image/2pt_ges.png}
  \caption{2ポイントと判別するフレーム（腕が挙がっていない状態）}
  \label{fig:2gesture} % ← ラベルを修正しました
\end{figure}

\section{統合手法を用いた判別}

\chapter{評価}

評価の目的，方法，結果，考察（研究の目的がどこまで達成できたのかについて），今後の課題について書く．
実験結果はグラフや表にまとめる．
実験結果に関しては必要に応じて，統計的検定を行う．
考察に関してはその根拠となる実験結果を示すこと．

\chapter{まとめ}

研究の目的と結果を簡潔に書く．
今後の課題に関して簡潔に書く．

\acknowledgement %謝辞

本研究を進めるにあたり，終始ご指導下さったXX教授に深く感謝いたします．

また，音声認識に関して協力していただいた知能機械工学課程YY教授に厚くお礼申し上げます．
ほかに協力してもらった人も書いておく．

北村研究室の同輩諸氏には，
日頃から多くのご助言やご支援をいただき，大変感謝しています．

最後に，4年間大学に通わせてくれた両親に，心から感謝しています．

\bibliographystyle{junsrt}
\bibliography{sample} 

\end{document}